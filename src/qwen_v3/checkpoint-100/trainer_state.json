{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.2631578947368425,
  "eval_steps": 500,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05263157894736842,
      "grad_norm": 2.0012998580932617,
      "learning_rate": 0.0002,
      "loss": 3.7408,
      "step": 1
    },
    {
      "epoch": 0.10526315789473684,
      "grad_norm": 1.8765617609024048,
      "learning_rate": 0.0004,
      "loss": 3.4873,
      "step": 2
    },
    {
      "epoch": 0.15789473684210525,
      "grad_norm": 1.3329030275344849,
      "learning_rate": 0.0006,
      "loss": 3.4745,
      "step": 3
    },
    {
      "epoch": 0.21052631578947367,
      "grad_norm": 1.8394194841384888,
      "learning_rate": 0.0008,
      "loss": 3.4334,
      "step": 4
    },
    {
      "epoch": 0.2631578947368421,
      "grad_norm": 1.4002660512924194,
      "learning_rate": 0.001,
      "loss": 3.053,
      "step": 5
    },
    {
      "epoch": 0.3157894736842105,
      "grad_norm": 0.847804069519043,
      "learning_rate": 0.000999726628670463,
      "loss": 2.9475,
      "step": 6
    },
    {
      "epoch": 0.3684210526315789,
      "grad_norm": 0.8489276766777039,
      "learning_rate": 0.0009989068136093873,
      "loss": 2.6656,
      "step": 7
    },
    {
      "epoch": 0.42105263157894735,
      "grad_norm": 1.6004998683929443,
      "learning_rate": 0.0009975414512725057,
      "loss": 2.455,
      "step": 8
    },
    {
      "epoch": 0.47368421052631576,
      "grad_norm": 0.7251191735267639,
      "learning_rate": 0.0009956320346634876,
      "loss": 2.2228,
      "step": 9
    },
    {
      "epoch": 0.5263157894736842,
      "grad_norm": 0.7267417907714844,
      "learning_rate": 0.0009931806517013613,
      "loss": 2.2787,
      "step": 10
    },
    {
      "epoch": 0.5789473684210527,
      "grad_norm": 0.8033808469772339,
      "learning_rate": 0.0009901899829374047,
      "loss": 2.1731,
      "step": 11
    },
    {
      "epoch": 0.631578947368421,
      "grad_norm": 0.8892956972122192,
      "learning_rate": 0.000986663298624003,
      "loss": 1.9033,
      "step": 12
    },
    {
      "epoch": 0.6842105263157895,
      "grad_norm": 2.893173933029175,
      "learning_rate": 0.0009826044551386743,
      "loss": 1.8568,
      "step": 13
    },
    {
      "epoch": 0.7368421052631579,
      "grad_norm": 0.706631600856781,
      "learning_rate": 0.0009780178907671788,
      "loss": 1.6964,
      "step": 14
    },
    {
      "epoch": 0.7894736842105263,
      "grad_norm": 0.6870317459106445,
      "learning_rate": 0.0009729086208503173,
      "loss": 1.761,
      "step": 15
    },
    {
      "epoch": 0.8421052631578947,
      "grad_norm": 0.7079631686210632,
      "learning_rate": 0.0009672822322997304,
      "loss": 1.8552,
      "step": 16
    },
    {
      "epoch": 0.8947368421052632,
      "grad_norm": 0.609372615814209,
      "learning_rate": 0.0009611448774886924,
      "loss": 1.7246,
      "step": 17
    },
    {
      "epoch": 0.9473684210526315,
      "grad_norm": 5.147844314575195,
      "learning_rate": 0.0009545032675245813,
      "loss": 1.737,
      "step": 18
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7671868801116943,
      "learning_rate": 0.0009473646649103818,
      "loss": 1.7339,
      "step": 19
    },
    {
      "epoch": 1.0526315789473684,
      "grad_norm": 0.6063569188117981,
      "learning_rate": 0.0009397368756032445,
      "loss": 1.4564,
      "step": 20
    },
    {
      "epoch": 1.1052631578947367,
      "grad_norm": 0.5877044796943665,
      "learning_rate": 0.000931628240478787,
      "loss": 1.5733,
      "step": 21
    },
    {
      "epoch": 1.1578947368421053,
      "grad_norm": 0.789560079574585,
      "learning_rate": 0.0009230476262104677,
      "loss": 1.5174,
      "step": 22
    },
    {
      "epoch": 1.2105263157894737,
      "grad_norm": 1.3215601444244385,
      "learning_rate": 0.00091400441557401,
      "loss": 1.6366,
      "step": 23
    },
    {
      "epoch": 1.263157894736842,
      "grad_norm": 0.7679189443588257,
      "learning_rate": 0.0009045084971874737,
      "loss": 1.4679,
      "step": 24
    },
    {
      "epoch": 1.3157894736842106,
      "grad_norm": 0.538375973701477,
      "learning_rate": 0.0008945702546981969,
      "loss": 1.4612,
      "step": 25
    },
    {
      "epoch": 1.368421052631579,
      "grad_norm": 0.5322723984718323,
      "learning_rate": 0.0008842005554284296,
      "loss": 1.4105,
      "step": 26
    },
    {
      "epoch": 1.4210526315789473,
      "grad_norm": 0.5696731209754944,
      "learning_rate": 0.000873410738492077,
      "loss": 1.4268,
      "step": 27
    },
    {
      "epoch": 1.4736842105263157,
      "grad_norm": 0.6487371921539307,
      "learning_rate": 0.0008622126023955446,
      "loss": 1.5571,
      "step": 28
    },
    {
      "epoch": 1.526315789473684,
      "grad_norm": 0.5644492506980896,
      "learning_rate": 0.0008506183921362443,
      "loss": 1.501,
      "step": 29
    },
    {
      "epoch": 1.5789473684210527,
      "grad_norm": 0.6791591048240662,
      "learning_rate": 0.0008386407858128706,
      "loss": 1.5987,
      "step": 30
    },
    {
      "epoch": 1.631578947368421,
      "grad_norm": 0.9340986609458923,
      "learning_rate": 0.0008262928807620843,
      "loss": 1.2667,
      "step": 31
    },
    {
      "epoch": 1.6842105263157894,
      "grad_norm": 0.5237457156181335,
      "learning_rate": 0.0008135881792367685,
      "loss": 1.3948,
      "step": 32
    },
    {
      "epoch": 1.736842105263158,
      "grad_norm": 0.4777449369430542,
      "learning_rate": 0.0008005405736415125,
      "loss": 1.3771,
      "step": 33
    },
    {
      "epoch": 1.7894736842105263,
      "grad_norm": 0.47665002942085266,
      "learning_rate": 0.0007871643313414718,
      "loss": 1.3668,
      "step": 34
    },
    {
      "epoch": 1.8421052631578947,
      "grad_norm": 0.5064885020256042,
      "learning_rate": 0.0007734740790612135,
      "loss": 1.5173,
      "step": 35
    },
    {
      "epoch": 1.8947368421052633,
      "grad_norm": 0.5770494341850281,
      "learning_rate": 0.0007594847868906076,
      "loss": 1.5105,
      "step": 36
    },
    {
      "epoch": 1.9473684210526314,
      "grad_norm": 0.4815067648887634,
      "learning_rate": 0.0007452117519152541,
      "loss": 1.6214,
      "step": 37
    },
    {
      "epoch": 2.0,
      "grad_norm": 3.3964715003967285,
      "learning_rate": 0.000730670581489344,
      "loss": 1.5179,
      "step": 38
    },
    {
      "epoch": 2.0526315789473686,
      "grad_norm": 0.46436360478401184,
      "learning_rate": 0.0007158771761692464,
      "loss": 1.3311,
      "step": 39
    },
    {
      "epoch": 2.1052631578947367,
      "grad_norm": 0.5293481945991516,
      "learning_rate": 0.0007008477123264848,
      "loss": 1.379,
      "step": 40
    },
    {
      "epoch": 2.1578947368421053,
      "grad_norm": 0.5353915691375732,
      "learning_rate": 0.0006855986244591103,
      "loss": 1.4086,
      "step": 41
    },
    {
      "epoch": 2.2105263157894735,
      "grad_norm": 0.530144453048706,
      "learning_rate": 0.0006701465872208216,
      "loss": 1.2428,
      "step": 42
    },
    {
      "epoch": 2.263157894736842,
      "grad_norm": 0.5092130899429321,
      "learning_rate": 0.0006545084971874737,
      "loss": 1.1772,
      "step": 43
    },
    {
      "epoch": 2.3157894736842106,
      "grad_norm": 0.5676788687705994,
      "learning_rate": 0.0006387014543809223,
      "loss": 1.2922,
      "step": 44
    },
    {
      "epoch": 2.3684210526315788,
      "grad_norm": 0.5673858523368835,
      "learning_rate": 0.0006227427435703996,
      "loss": 1.193,
      "step": 45
    },
    {
      "epoch": 2.4210526315789473,
      "grad_norm": 0.50972980260849,
      "learning_rate": 0.0006066498153718734,
      "loss": 1.2031,
      "step": 46
    },
    {
      "epoch": 2.473684210526316,
      "grad_norm": 0.5475641489028931,
      "learning_rate": 0.000590440267166055,
      "loss": 1.2954,
      "step": 47
    },
    {
      "epoch": 2.526315789473684,
      "grad_norm": 0.5294855237007141,
      "learning_rate": 0.000574131823855921,
      "loss": 1.4368,
      "step": 48
    },
    {
      "epoch": 2.5789473684210527,
      "grad_norm": 0.573654055595398,
      "learning_rate": 0.0005577423184847932,
      "loss": 1.2981,
      "step": 49
    },
    {
      "epoch": 2.6315789473684212,
      "grad_norm": 0.5670514106750488,
      "learning_rate": 0.0005412896727361663,
      "loss": 1.1664,
      "step": 50
    },
    {
      "epoch": 2.6842105263157894,
      "grad_norm": 0.5350629091262817,
      "learning_rate": 0.0005247918773366112,
      "loss": 1.2994,
      "step": 51
    },
    {
      "epoch": 2.736842105263158,
      "grad_norm": 0.5803784728050232,
      "learning_rate": 0.0005082669723831793,
      "loss": 1.2161,
      "step": 52
    },
    {
      "epoch": 2.7894736842105265,
      "grad_norm": 0.5372285842895508,
      "learning_rate": 0.0004917330276168208,
      "loss": 1.2469,
      "step": 53
    },
    {
      "epoch": 2.8421052631578947,
      "grad_norm": 0.49943020939826965,
      "learning_rate": 0.0004752081226633888,
      "loss": 1.2617,
      "step": 54
    },
    {
      "epoch": 2.8947368421052633,
      "grad_norm": 0.5401052236557007,
      "learning_rate": 0.0004587103272638339,
      "loss": 1.2124,
      "step": 55
    },
    {
      "epoch": 2.9473684210526314,
      "grad_norm": 0.49518728256225586,
      "learning_rate": 0.00044225768151520694,
      "loss": 1.1681,
      "step": 56
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.5184255242347717,
      "learning_rate": 0.00042586817614407896,
      "loss": 1.0971,
      "step": 57
    },
    {
      "epoch": 3.0526315789473686,
      "grad_norm": 0.4790413975715637,
      "learning_rate": 0.0004095597328339452,
      "loss": 1.2087,
      "step": 58
    },
    {
      "epoch": 3.1052631578947367,
      "grad_norm": 0.5144287943840027,
      "learning_rate": 0.00039335018462812664,
      "loss": 1.1667,
      "step": 59
    },
    {
      "epoch": 3.1578947368421053,
      "grad_norm": 0.465639591217041,
      "learning_rate": 0.00037725725642960046,
      "loss": 1.0079,
      "step": 60
    },
    {
      "epoch": 3.2105263157894735,
      "grad_norm": 0.5141284465789795,
      "learning_rate": 0.00036129854561907783,
      "loss": 1.0262,
      "step": 61
    },
    {
      "epoch": 3.263157894736842,
      "grad_norm": 0.5150156021118164,
      "learning_rate": 0.00034549150281252633,
      "loss": 1.0786,
      "step": 62
    },
    {
      "epoch": 3.3157894736842106,
      "grad_norm": 0.5478826761245728,
      "learning_rate": 0.0003298534127791785,
      "loss": 1.0077,
      "step": 63
    },
    {
      "epoch": 3.3684210526315788,
      "grad_norm": 0.5902794599533081,
      "learning_rate": 0.0003144013755408895,
      "loss": 1.2082,
      "step": 64
    },
    {
      "epoch": 3.4210526315789473,
      "grad_norm": 0.5743476152420044,
      "learning_rate": 0.0002991522876735154,
      "loss": 1.1339,
      "step": 65
    },
    {
      "epoch": 3.473684210526316,
      "grad_norm": 0.5281057357788086,
      "learning_rate": 0.0002841228238307536,
      "loss": 1.2452,
      "step": 66
    },
    {
      "epoch": 3.526315789473684,
      "grad_norm": 0.5573218464851379,
      "learning_rate": 0.00026932941851065615,
      "loss": 1.2912,
      "step": 67
    },
    {
      "epoch": 3.5789473684210527,
      "grad_norm": 0.5793960094451904,
      "learning_rate": 0.0002547882480847461,
      "loss": 1.2026,
      "step": 68
    },
    {
      "epoch": 3.6315789473684212,
      "grad_norm": 0.6382402777671814,
      "learning_rate": 0.00024051521310939256,
      "loss": 1.1544,
      "step": 69
    },
    {
      "epoch": 3.6842105263157894,
      "grad_norm": 0.5797765851020813,
      "learning_rate": 0.00022652592093878665,
      "loss": 0.9687,
      "step": 70
    },
    {
      "epoch": 3.736842105263158,
      "grad_norm": 0.5431036949157715,
      "learning_rate": 0.0002128356686585282,
      "loss": 1.0204,
      "step": 71
    },
    {
      "epoch": 3.7894736842105265,
      "grad_norm": 0.5652750134468079,
      "learning_rate": 0.00019945942635848747,
      "loss": 1.0789,
      "step": 72
    },
    {
      "epoch": 3.8421052631578947,
      "grad_norm": 0.5254873037338257,
      "learning_rate": 0.00018641182076323148,
      "loss": 1.021,
      "step": 73
    },
    {
      "epoch": 3.8947368421052633,
      "grad_norm": 0.5985981822013855,
      "learning_rate": 0.00017370711923791565,
      "loss": 1.1086,
      "step": 74
    },
    {
      "epoch": 3.9473684210526314,
      "grad_norm": 0.5673744082450867,
      "learning_rate": 0.00016135921418712956,
      "loss": 1.0971,
      "step": 75
    },
    {
      "epoch": 4.0,
      "grad_norm": 0.6191980242729187,
      "learning_rate": 0.00014938160786375572,
      "loss": 1.0619,
      "step": 76
    },
    {
      "epoch": 4.052631578947368,
      "grad_norm": 0.5454327464103699,
      "learning_rate": 0.00013778739760445552,
      "loss": 0.9377,
      "step": 77
    },
    {
      "epoch": 4.105263157894737,
      "grad_norm": 0.5011323094367981,
      "learning_rate": 0.0001265892615079232,
      "loss": 1.0355,
      "step": 78
    },
    {
      "epoch": 4.157894736842105,
      "grad_norm": 0.5432517528533936,
      "learning_rate": 0.0001157994445715706,
      "loss": 0.9871,
      "step": 79
    },
    {
      "epoch": 4.2105263157894735,
      "grad_norm": 0.5964300036430359,
      "learning_rate": 0.00010542974530180327,
      "loss": 1.0024,
      "step": 80
    },
    {
      "epoch": 4.2631578947368425,
      "grad_norm": 0.5427984595298767,
      "learning_rate": 9.549150281252633e-05,
      "loss": 0.9245,
      "step": 81
    },
    {
      "epoch": 4.315789473684211,
      "grad_norm": 0.558606743812561,
      "learning_rate": 8.599558442598998e-05,
      "loss": 1.0688,
      "step": 82
    },
    {
      "epoch": 4.368421052631579,
      "grad_norm": 0.5995463728904724,
      "learning_rate": 7.695237378953224e-05,
      "loss": 1.0733,
      "step": 83
    },
    {
      "epoch": 4.421052631578947,
      "grad_norm": 0.5315749645233154,
      "learning_rate": 6.837175952121305e-05,
      "loss": 0.9918,
      "step": 84
    },
    {
      "epoch": 4.473684210526316,
      "grad_norm": 0.5230106115341187,
      "learning_rate": 6.026312439675552e-05,
      "loss": 0.9552,
      "step": 85
    },
    {
      "epoch": 4.526315789473684,
      "grad_norm": 0.5520597100257874,
      "learning_rate": 5.2635335089618264e-05,
      "loss": 1.0336,
      "step": 86
    },
    {
      "epoch": 4.578947368421053,
      "grad_norm": 0.548653781414032,
      "learning_rate": 4.5496732475418745e-05,
      "loss": 1.2208,
      "step": 87
    },
    {
      "epoch": 4.631578947368421,
      "grad_norm": 0.5342954993247986,
      "learning_rate": 3.885512251130763e-05,
      "loss": 1.0201,
      "step": 88
    },
    {
      "epoch": 4.684210526315789,
      "grad_norm": 0.5547672510147095,
      "learning_rate": 3.271776770026963e-05,
      "loss": 1.1429,
      "step": 89
    },
    {
      "epoch": 4.7368421052631575,
      "grad_norm": 0.6036689877510071,
      "learning_rate": 2.709137914968268e-05,
      "loss": 1.0274,
      "step": 90
    },
    {
      "epoch": 4.7894736842105265,
      "grad_norm": 0.6126114726066589,
      "learning_rate": 2.198210923282118e-05,
      "loss": 1.0699,
      "step": 91
    },
    {
      "epoch": 4.842105263157895,
      "grad_norm": 0.6254516839981079,
      "learning_rate": 1.7395544861325717e-05,
      "loss": 1.0557,
      "step": 92
    },
    {
      "epoch": 4.894736842105263,
      "grad_norm": 0.6092284917831421,
      "learning_rate": 1.3336701375997129e-05,
      "loss": 1.0819,
      "step": 93
    },
    {
      "epoch": 4.947368421052632,
      "grad_norm": 0.5577735900878906,
      "learning_rate": 9.810017062595322e-06,
      "loss": 1.0086,
      "step": 94
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.6320582628250122,
      "learning_rate": 6.819348298638839e-06,
      "loss": 0.9395,
      "step": 95
    },
    {
      "epoch": 5.052631578947368,
      "grad_norm": 0.5272274017333984,
      "learning_rate": 4.367965336512402e-06,
      "loss": 0.8726,
      "step": 96
    },
    {
      "epoch": 5.105263157894737,
      "grad_norm": 0.5536814332008362,
      "learning_rate": 2.458548727494292e-06,
      "loss": 0.95,
      "step": 97
    },
    {
      "epoch": 5.157894736842105,
      "grad_norm": 0.5366617441177368,
      "learning_rate": 1.0931863906127326e-06,
      "loss": 1.0836,
      "step": 98
    },
    {
      "epoch": 5.2105263157894735,
      "grad_norm": 0.5562803745269775,
      "learning_rate": 2.733713295369755e-07,
      "loss": 1.0203,
      "step": 99
    },
    {
      "epoch": 5.2631578947368425,
      "grad_norm": 0.5377005338668823,
      "learning_rate": 0.0,
      "loss": 1.2057,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 100,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9238173295411200.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
